---
title: "Non-Parametric Statistics - Problem Sets"
author: "Silvana, Florencia Luque, Simon Schmetz"
date: "2025-03-14"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

In the following document, the solutions to three problem sets from Prof. Eduardo García\-Portugués book on nonparametric Statistics (https://bookdown.org/egarpor/NP-UC3M/) as final assignment for the Course in Nonparametric Statistics at Universidad Carlos III de Madrid. 
*Contributions made to this document are made are equal among each of the three authors*


# Excercise 4.21


```{r cars}
#TODO: Silvana
```


# Excercises 5.10 
Investigate the accuracy of the naive bootstrap confidence intervals implemented in *np::npplot*. To do so:

1. Simulate $M=500$ samples of size $n =100$ from the regression model $Y=m(X)+\varepsilon$, where $m(x)=0.25x^{2}-0.75x+3$, $X\sim N(0,1.5^{2})$, and $\varepsilon \sim N(0,0.75^{2})$.

```{r,warning=FALSE}
library(np)
set.seed(1234)
M = 500
n = 100
y_muestras = matrix(0,ncol = n,nrow = M)
m = function(a){
  0.25*a^2-0.75*a+3
}
for (i in 1:500){
  x = rnorm(100,0,1.5)
  epsilon = rnorm(100,0,0.75)
  y_muestras[i,] = m(x)+epsilon
}
```

2. Compute the 95\% confidence intervals for $m(x)$  along $x\gets seq(-5, 5, by = 0.1)$, for each of the  M  samples. Do it for the normal approximation and quantile-based confidence intervals.
```{r}
x_grid = seq(-5,5,by=0.1)

```
3. Check if  $m(x)$  belongs to each of the confidence intervals, for each  x.
```{r}

```
4. Approximate the actual coverage of the confidence intervals.
```{r}

```
# Excercise 6.8

```{r}
library(goftest)
library(nortest)
library(latex2exp)
```


```{r}

# Function for Simulation of p-values
simulate_pvalues <- function(mu_samp=0, sd_samp=1 , M, n, alpha, dist = "normal") {

  # generate p-Values for samples from Normal
  pvalues <- sapply(1:M, function(i) {
    
    if(dist == "normal"){
      x = rnorm(n, mean = mu_samp, sd = sd_samp)
    }

    if(dist == "t-students"){
      x = rt(n, df = 10, ncp = mu_samp)
    }
    
    pval_ks = ks.test(x, "pnorm", mean = 0, sd = 1)$p.value
    pval_cvm = goftest::cvm.test(x = x, null = "pnorm")$p.value
    pval_ad = goftest::ad.test(x = x, null = "pnorm")$p.value
    return(c(pval_ks, pval_ad, pval_cvm))
  })
  
  # get rejection rates
  ks_rejection_rate = sum(pvalues[1,] < alpha) / M
  cvm_rejection_rate = sum(pvalues[2,] < alpha) / M
  ad_rejection_rate = sum(pvalues[3,] < alpha) / M
  
  # plot
  par(mfrow = c(1, 3))
  hist(pvalues[1,], breaks = seq(0, 1, l = 20), probability = TRUE,
       main = paste("Kolmogorov-Smirnov", "\nRejection Rate:", round(ks_rejection_rate, 2)), ylim = c(0, 10))
  abline(h = 1, col = "red")
  
  hist(pvalues[2,], breaks = seq(0, 1, l = 20), probability = TRUE,
       main = paste("Cramer von Mises", "\nRejection Rate:", round(cvm_rejection_rate, 2)), ylim = c(0, 10))
  abline(h = 1, col = "red")
  
  hist(pvalues[3,], breaks = seq(0, 1, l = 20), probability = TRUE,
       main = paste("Anderson-Darling", "\nRejection Rate:", round(ad_rejection_rate, 2)), ylim = c(0, 10))
  abline(h = 1, col = "red")
}


```

```{r}
# H0 True
set.seed(123)
simulate_pvalues(mu_samp = 0, sd_samp = 1, M = 1000, n = 25, alpha = 0.05)
simulate_pvalues(mu_samp = 0, sd_samp = 1, M = 1000, n = 25, alpha = 0.1)
simulate_pvalues(mu_samp = 0, sd_samp = 1, M = 1000, n = 100, alpha = 0.1)

```
```{r}
# H0 False
simulate_pvalues(mu_samp = 0.25, sd_samp = 1, M = 1000, n = 25, alpha = 0.05)
simulate_pvalues(mu_samp = 0.25, sd_samp = 1, M = 1000, n = 50, alpha = 0.05)
simulate_pvalues(mu_samp = 0.50, sd_samp = 1, M = 1000, n = 25, alpha = 0.05)
```

```{r}
# 
simulate_pvalues(mu_samp = 0,M = 1000, n = 50, alpha = 0.5, dist = "t-students")
```


